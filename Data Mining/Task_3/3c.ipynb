{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import norm  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline    \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import precision_score, recall_score, plot_confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bagusariyono/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('/Users/bagusariyono/Downloads/UPDATED_NLP_COURSE/TextFiles/smsspamcollection.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "0      ham   \n",
       "1      ham   \n",
       "2     spam   \n",
       "3      ham   \n",
       "4      ham   \n",
       "...    ...   \n",
       "5567  spam   \n",
       "5568   ham   \n",
       "5569   ham   \n",
       "5570   ham   \n",
       "5571   ham   \n",
       "\n",
       "                                                                                                                                                               message  \\\n",
       "0                                                      Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...   \n",
       "1                                                                                                                                        Ok lar... Joking wif u oni...   \n",
       "2          Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
       "3                                                                                                                    U dun say so early hor... U c already then say...   \n",
       "4                                                                                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "...                                                                                                                                                                ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.   \n",
       "5568                                                                                                                              Will ü b going to esplanade fr home?   \n",
       "5569                                                                                                         Pity, * was in mood for that. So...any other suggestions?   \n",
       "5570                                     The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl. Its true to its name   \n",
       "\n",
       "      length  punct  \n",
       "0        111      9  \n",
       "1         29      6  \n",
       "2        155      6  \n",
       "3         49      6  \n",
       "4         61      2  \n",
       "...      ...    ...  \n",
       "5567     160      8  \n",
       "5568      36      1  \n",
       "5569      57      7  \n",
       "5570     125      1  \n",
       "5571      26      1  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
      "20                                                                                                                      Is that seriously how you spell his name?\n",
      "21                                                                                                                I‘m going to try for 2 months ha ha only joking\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sms['message'][19:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(Text):\n",
    "    sms = re.sub('[^a-zA-Z]', ' ', Text)\n",
    "    return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms[\"numpunct\"] = sms['message'].apply(Clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    England v Macedonia   dont miss the goals team news  Txt ur national team to       eg ENGLAND to       Try WALES  SCOTLAND  txt       POBOXox     W  WQ    \n",
      "20                                                                                                                      Is that seriously how you spell his name \n",
      "21                                                                                                                I m going to try for   months ha ha only joking\n",
      "Name: numpunct, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sms['numpunct'][19:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms[\"token\"]=sms.apply(lambda row: nltk.word_tokenize(row[\"numpunct\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "      <th>numpunct</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>Go until jurong point  crazy   Available only in bugis n great world la e buffet    Cine there got amore wat</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, got, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar    Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s</td>\n",
       "      <td>[Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>U dun say so early hor    U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>Nah I don t think he goes to usf  he lives around here though</td>\n",
       "      <td>[Nah, I, don, t, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>This is the  nd time we have tried   contact u  U have won the      Pound prize    claim is easy  call              NOW   Only   p per minute  BT national rate</td>\n",
       "      <td>[This, is, the, nd, time, we, have, tried, contact, u, U, have, won, the, Pound, prize, claim, is, easy, call, NOW, Only, p, per, minute, BT, national, rate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>Will   b going to esplanade fr home</td>\n",
       "      <td>[Will, b, going, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Pity    was in mood for that  So   any other suggestions</td>\n",
       "      <td>[Pity, was, in, mood, for, that, So, any, other, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>The guy did some bitching but I acted like i d be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>[The, guy, did, some, bitching, but, I, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Rofl  Its true to its name</td>\n",
       "      <td>[Rofl, Its, true, to, its, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "0      ham   \n",
       "1      ham   \n",
       "2     spam   \n",
       "3      ham   \n",
       "4      ham   \n",
       "...    ...   \n",
       "5567  spam   \n",
       "5568   ham   \n",
       "5569   ham   \n",
       "5570   ham   \n",
       "5571   ham   \n",
       "\n",
       "                                                                                                                                                               message  \\\n",
       "0                                                      Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...   \n",
       "1                                                                                                                                        Ok lar... Joking wif u oni...   \n",
       "2          Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
       "3                                                                                                                    U dun say so early hor... U c already then say...   \n",
       "4                                                                                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "...                                                                                                                                                                ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.   \n",
       "5568                                                                                                                              Will ü b going to esplanade fr home?   \n",
       "5569                                                                                                         Pity, * was in mood for that. So...any other suggestions?   \n",
       "5570                                     The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl. Its true to its name   \n",
       "\n",
       "      length  punct  \\\n",
       "0        111      9   \n",
       "1         29      6   \n",
       "2        155      6   \n",
       "3         49      6   \n",
       "4         61      2   \n",
       "...      ...    ...   \n",
       "5567     160      8   \n",
       "5568      36      1   \n",
       "5569      57      7   \n",
       "5570     125      1   \n",
       "5571      26      1   \n",
       "\n",
       "                                                                                                                                                              numpunct  \\\n",
       "0                                                      Go until jurong point  crazy   Available only in bugis n great world la e buffet    Cine there got amore wat      \n",
       "1                                                                                                                                        Ok lar    Joking wif u oni      \n",
       "2          Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s   \n",
       "3                                                                                                                    U dun say so early hor    U c already then say      \n",
       "4                                                                                                        Nah I don t think he goes to usf  he lives around here though   \n",
       "...                                                                                                                                                                ...   \n",
       "5567  This is the  nd time we have tried   contact u  U have won the      Pound prize    claim is easy  call              NOW   Only   p per minute  BT national rate    \n",
       "5568                                                                                                                              Will   b going to esplanade fr home    \n",
       "5569                                                                                                         Pity    was in mood for that  So   any other suggestions    \n",
       "5570                                     The guy did some bitching but I acted like i d be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl  Its true to its name   \n",
       "\n",
       "                                                                                                                                                              token  \n",
       "0                                       [Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, got, amore, wat]  \n",
       "1                                                                                                                                    [Ok, lar, Joking, wif, u, oni]  \n",
       "2     [Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]  \n",
       "3                                                                                                           [U, dun, say, so, early, hor, U, c, already, then, say]  \n",
       "4                                                                                       [Nah, I, don, t, think, he, goes, to, usf, he, lives, around, here, though]  \n",
       "...                                                                                                                                                             ...  \n",
       "5567  [This, is, the, nd, time, we, have, tried, contact, u, U, have, won, the, Pound, prize, claim, is, easy, call, NOW, Only, p, per, minute, BT, national, rate]  \n",
       "5568                                                                                                                      [Will, b, going, to, esplanade, fr, home]  \n",
       "5569                                                                                                  [Pity, was, in, mood, for, that, So, any, other, suggestions]  \n",
       "5570      [The, guy, did, some, bitching, but, I, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]  \n",
       "5571                                                                                                                               [Rofl, Its, true, to, its, name]  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    [England, v, Macedonia, dont, miss, the, goals, team, news, Txt, ur, national, team, to, eg, ENGLAND, to, Try, WALES, SCOTLAND, txt, POBOXox, W, WQ]\n",
      "20                                                                                                       [Is, that, seriously, how, you, spell, his, name]\n",
      "21                                                                                               [I, m, going, to, try, for, months, ha, ha, only, joking]\n",
      "Name: token, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sms['token'][19:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    lemmas = [lemma.lemmatize(word, pos ='v') for word in text]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "      <th>numpunct</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>Go until jurong point  crazy   Available only in bugis n great world la e buffet    Cine there got amore wat</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, got, amore, wat]</td>\n",
       "      <td>[Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, get, amore, wat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Ok lar    Joking wif u oni</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "      <td>[Ok, lar, Joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s</td>\n",
       "      <td>[Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]</td>\n",
       "      <td>[Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>U dun say so early hor    U c already then say</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, then, say]</td>\n",
       "      <td>[U, dun, say, so, early, hor, U, c, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>Nah I don t think he goes to usf  he lives around here though</td>\n",
       "      <td>[Nah, I, don, t, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[Nah, I, don, t, think, he, go, to, usf, he, live, around, here, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>This is the  nd time we have tried   contact u  U have won the      Pound prize    claim is easy  call              NOW   Only   p per minute  BT national rate</td>\n",
       "      <td>[This, is, the, nd, time, we, have, tried, contact, u, U, have, won, the, Pound, prize, claim, is, easy, call, NOW, Only, p, per, minute, BT, national, rate]</td>\n",
       "      <td>[This, be, the, nd, time, we, have, try, contact, u, U, have, win, the, Pound, prize, claim, be, easy, call, NOW, Only, p, per, minute, BT, national, rate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>Will   b going to esplanade fr home</td>\n",
       "      <td>[Will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[Will, b, go, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Pity    was in mood for that  So   any other suggestions</td>\n",
       "      <td>[Pity, was, in, mood, for, that, So, any, other, suggestions]</td>\n",
       "      <td>[Pity, be, in, mood, for, that, So, any, other, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>The guy did some bitching but I acted like i d be interested in buying something else next week and he gave it to us for free</td>\n",
       "      <td>[The, guy, did, some, bitching, but, I, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]</td>\n",
       "      <td>[The, guy, do, some, bitch, but, I, act, like, i, d, be, interest, in, buy, something, else, next, week, and, he, give, it, to, us, for, free]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Rofl  Its true to its name</td>\n",
       "      <td>[Rofl, Its, true, to, its, name]</td>\n",
       "      <td>[Rofl, Its, true, to, its, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "0      ham   \n",
       "1      ham   \n",
       "2     spam   \n",
       "3      ham   \n",
       "4      ham   \n",
       "...    ...   \n",
       "5567  spam   \n",
       "5568   ham   \n",
       "5569   ham   \n",
       "5570   ham   \n",
       "5571   ham   \n",
       "\n",
       "                                                                                                                                                               message  \\\n",
       "0                                                      Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...   \n",
       "1                                                                                                                                        Ok lar... Joking wif u oni...   \n",
       "2          Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
       "3                                                                                                                    U dun say so early hor... U c already then say...   \n",
       "4                                                                                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "...                                                                                                                                                                ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy, call 087187272008 NOW1! Only 10p per minute. BT-national-rate.   \n",
       "5568                                                                                                                              Will ü b going to esplanade fr home?   \n",
       "5569                                                                                                         Pity, * was in mood for that. So...any other suggestions?   \n",
       "5570                                     The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl. Its true to its name   \n",
       "\n",
       "      length  punct  \\\n",
       "0        111      9   \n",
       "1         29      6   \n",
       "2        155      6   \n",
       "3         49      6   \n",
       "4         61      2   \n",
       "...      ...    ...   \n",
       "5567     160      8   \n",
       "5568      36      1   \n",
       "5569      57      7   \n",
       "5570     125      1   \n",
       "5571      26      1   \n",
       "\n",
       "                                                                                                                                                              numpunct  \\\n",
       "0                                                      Go until jurong point  crazy   Available only in bugis n great world la e buffet    Cine there got amore wat      \n",
       "1                                                                                                                                        Ok lar    Joking wif u oni      \n",
       "2          Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s   \n",
       "3                                                                                                                    U dun say so early hor    U c already then say      \n",
       "4                                                                                                        Nah I don t think he goes to usf  he lives around here though   \n",
       "...                                                                                                                                                                ...   \n",
       "5567  This is the  nd time we have tried   contact u  U have won the      Pound prize    claim is easy  call              NOW   Only   p per minute  BT national rate    \n",
       "5568                                                                                                                              Will   b going to esplanade fr home    \n",
       "5569                                                                                                         Pity    was in mood for that  So   any other suggestions    \n",
       "5570                                     The guy did some bitching but I acted like i d be interested in buying something else next week and he gave it to us for free   \n",
       "5571                                                                                                                                        Rofl  Its true to its name   \n",
       "\n",
       "                                                                                                                                                              token  \\\n",
       "0                                       [Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, got, amore, wat]   \n",
       "1                                                                                                                                    [Ok, lar, Joking, wif, u, oni]   \n",
       "2     [Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]   \n",
       "3                                                                                                           [U, dun, say, so, early, hor, U, c, already, then, say]   \n",
       "4                                                                                       [Nah, I, don, t, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "...                                                                                                                                                             ...   \n",
       "5567  [This, is, the, nd, time, we, have, tried, contact, u, U, have, won, the, Pound, prize, claim, is, easy, call, NOW, Only, p, per, minute, BT, national, rate]   \n",
       "5568                                                                                                                      [Will, b, going, to, esplanade, fr, home]   \n",
       "5569                                                                                                  [Pity, was, in, mood, for, that, So, any, other, suggestions]   \n",
       "5570      [The, guy, did, some, bitching, but, I, acted, like, i, d, be, interested, in, buying, something, else, next, week, and, he, gave, it, to, us, for, free]   \n",
       "5571                                                                                                                               [Rofl, Its, true, to, its, name]   \n",
       "\n",
       "                                                                                                                                                              lemma  \n",
       "0                                       [Go, until, jurong, point, crazy, Available, only, in, bugis, n, great, world, la, e, buffet, Cine, there, get, amore, wat]  \n",
       "1                                                                                                                                    [Ok, lar, Joking, wif, u, oni]  \n",
       "2     [Free, entry, in, a, wkly, comp, to, win, FA, Cup, final, tkts, st, May, Text, FA, to, to, receive, entry, question, std, txt, rate, T, C, s, apply, over, s]  \n",
       "3                                                                                                           [U, dun, say, so, early, hor, U, c, already, then, say]  \n",
       "4                                                                                          [Nah, I, don, t, think, he, go, to, usf, he, live, around, here, though]  \n",
       "...                                                                                                                                                             ...  \n",
       "5567    [This, be, the, nd, time, we, have, try, contact, u, U, have, win, the, Pound, prize, claim, be, easy, call, NOW, Only, p, per, minute, BT, national, rate]  \n",
       "5568                                                                                                                         [Will, b, go, to, esplanade, fr, home]  \n",
       "5569                                                                                                   [Pity, be, in, mood, for, that, So, any, other, suggestions]  \n",
       "5570                 [The, guy, do, some, bitch, but, I, act, like, i, d, be, interest, in, buy, something, else, next, week, and, he, give, it, to, us, for, free]  \n",
       "5571                                                                                                                               [Rofl, Its, true, to, its, name]  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[\"lemma\"] = sms[\"token\"].apply(lemmatize)\n",
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    [England, v, Macedonia, dont, miss, the, goals, team, news, Txt, ur, national, team, to, eg, ENGLAND, to, Try, WALES, SCOTLAND, txt, POBOXox, W, WQ]\n",
      "20                                                                                                       [Is, that, seriously, how, you, spell, his, name]\n",
      "21                                                                                                    [I, m, go, to, try, for, months, ha, ha, only, joke]\n",
      "Name: lemma, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sms['lemma'][19:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist= []\n",
    "for i in sms[\"lemma\"]:\n",
    "    message = ' '.join([row for row in i])\n",
    "    wordlist.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['England v Macedonia dont miss the goals team news Txt ur national team to eg ENGLAND to Try WALES SCOTLAND txt POBOXox W WQ',\n",
       " 'Is that seriously how you spell his name',\n",
       " 'I m go to try for months ha ha only joke']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[19:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sms['lemma'] = LabelEncoder().fit_transform(sms['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wordlist\n",
    "y=sms['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove puctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvec = CountVectorizer()\n",
    "# X_count = countvec.fit_transform(wordlist).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 5627)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-d4c901e4852a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Feed the training data through the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtext_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \"\"\"\n\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 5627)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 5627)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_countvect = countvect.fit_transform(X_train)\n",
    "X_train_countvect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lemmatization\n",
    "# def lemma(text):\n",
    "#     text = unicode(message, 'utf8').lower()\n",
    "#     return[word.lemma for word in TextBlob(message).words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 6750)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aah',\n",
       " 'aaniye',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abdomen',\n",
       " 'abeg',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'abiola',\n",
       " 'abj',\n",
       " 'able',\n",
       " 'abnormally',\n",
       " 'aboutas',\n",
       " 'abroad',\n",
       " 'absence',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'aburo',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accenture',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accidant',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodation',\n",
       " 'accommodationvouchers',\n",
       " 'accomodate',\n",
       " 'accomodations',\n",
       " 'accordin',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accumulation',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'acid',\n",
       " 'acknowledgement',\n",
       " 'acl',\n",
       " 'acnt',\n",
       " 'aco',\n",
       " 'act',\n",
       " 'actin',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'addamsfa',\n",
       " 'addict',\n",
       " 'addie',\n",
       " 'address',\n",
       " 'adewale',\n",
       " 'adi',\n",
       " 'adjustable',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admirer',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'adore',\n",
       " 'adp',\n",
       " 'adress',\n",
       " 'adrian',\n",
       " 'adrink',\n",
       " 'ads',\n",
       " 'adsense',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisors',\n",
       " 'ae',\n",
       " 'aeronautics',\n",
       " 'aeroplane',\n",
       " 'afew',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affections',\n",
       " 'affidavit',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afternon',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agidhane',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahold',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'aight',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airtel',\n",
       " 'aiya',\n",
       " 'aiyah',\n",
       " 'aiyar',\n",
       " 'aiyo',\n",
       " 'aj',\n",
       " 'ajith',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akon',\n",
       " 'al',\n",
       " 'alaikkum',\n",
       " 'alaipayuthe',\n",
       " 'albi',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'aldrine',\n",
       " 'alert',\n",
       " 'alertfrom',\n",
       " 'aletter',\n",
       " 'alex',\n",
       " 'alfie',\n",
       " 'algarve',\n",
       " 'algebra',\n",
       " 'algorithms',\n",
       " 'ali',\n",
       " 'alian',\n",
       " 'alibi',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allalo',\n",
       " 'allday',\n",
       " 'alle',\n",
       " 'allo',\n",
       " 'allow',\n",
       " 'alot',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'alter',\n",
       " 'alternative',\n",
       " 'alto',\n",
       " 'aluable',\n",
       " 'alwa',\n",
       " 'alwys',\n",
       " 'amanda',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'ambrith',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amigos',\n",
       " 'amk',\n",
       " 'amla',\n",
       " 'amma',\n",
       " 'ammae',\n",
       " 'ammo',\n",
       " 'amnow',\n",
       " 'amore',\n",
       " 'amp',\n",
       " 'amplikater',\n",
       " 'amrca',\n",
       " 'amrita',\n",
       " 'ams',\n",
       " 'amt',\n",
       " 'amuse',\n",
       " 'amy',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'anand',\n",
       " 'anderson',\n",
       " 'andre',\n",
       " 'andres',\n",
       " 'andrews',\n",
       " 'andros',\n",
       " 'angels',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animation',\n",
       " 'anjie',\n",
       " 'anjola',\n",
       " 'anna',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annoncement',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'annoy',\n",
       " 'annoyin',\n",
       " 'annoying',\n",
       " 'anonymous',\n",
       " 'anot',\n",
       " 'ans',\n",
       " 'ansr',\n",
       " 'answer',\n",
       " 'answerin',\n",
       " 'answr',\n",
       " 'antelope',\n",
       " 'antha',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antibiotic',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyones',\n",
       " 'anyplaces',\n",
       " 'anythiing',\n",
       " 'anythin',\n",
       " 'anythingtomorrow',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'aom',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apeshit',\n",
       " 'aphex',\n",
       " 'apnt',\n",
       " 'apo',\n",
       " 'apologetic',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appendix',\n",
       " 'applausestore',\n",
       " 'apple',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appy',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aproach',\n",
       " 'apt',\n",
       " 'aptitude',\n",
       " 'aq',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabian',\n",
       " 'arcade',\n",
       " 'archive',\n",
       " 'ard',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arestaurant',\n",
       " 'aretaking',\n",
       " 'areyouunique',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'aries',\n",
       " 'arise',\n",
       " 'arithmetic',\n",
       " 'arm',\n",
       " 'armand',\n",
       " 'armenia',\n",
       " 'arms',\n",
       " 'arng',\n",
       " 'arngd',\n",
       " 'arnt',\n",
       " 'aroundn',\n",
       " 'arr',\n",
       " 'arrange',\n",
       " 'arrest',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrow',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'arty',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asda',\n",
       " 'ash',\n",
       " 'ashley',\n",
       " 'ashwini',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asjesus',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'askin',\n",
       " 'asking',\n",
       " 'aslamalaikkum',\n",
       " 'asleep',\n",
       " 'asp',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assessment',\n",
       " 'asshole',\n",
       " 'assistance',\n",
       " 'associate',\n",
       " 'asssssholeeee',\n",
       " 'assume',\n",
       " 'asthere',\n",
       " 'asthma',\n",
       " 'astne',\n",
       " 'astoundingly',\n",
       " 'astrology',\n",
       " 'astronomer',\n",
       " 'asus',\n",
       " 'asusual',\n",
       " 'athletic',\n",
       " 'athome',\n",
       " 'atlanta',\n",
       " 'atlast',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atrocious',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'atten',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attribute',\n",
       " 'atural',\n",
       " 'auction',\n",
       " 'audiitions',\n",
       " 'audition',\n",
       " 'audrey',\n",
       " 'audrie',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " 'aunties',\n",
       " 'aunts',\n",
       " 'aunty',\n",
       " 'aust',\n",
       " 'australia',\n",
       " 'authorise',\n",
       " 'auto',\n",
       " 'autocorrect',\n",
       " 'av',\n",
       " 'ava',\n",
       " 'availa',\n",
       " 'available',\n",
       " 'avalarr',\n",
       " 'avatar',\n",
       " 'avble',\n",
       " 'ave',\n",
       " 'avenge',\n",
       " 'avent',\n",
       " 'avenue',\n",
       " 'avin',\n",
       " 'avo',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'ax',\n",
       " 'axel',\n",
       " 'axis',\n",
       " 'ay',\n",
       " 'ayn',\n",
       " 'ayo',\n",
       " 'ba',\n",
       " 'baaaaaaaabe',\n",
       " 'baaaaabe',\n",
       " 'babe',\n",
       " 'babes',\n",
       " 'baby',\n",
       " 'babygoodbye',\n",
       " 'babyjontet',\n",
       " 'babysit',\n",
       " 'babysitting',\n",
       " 'bac',\n",
       " 'backdoor',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badly',\n",
       " 'badrith',\n",
       " 'bag',\n",
       " 'bahamas',\n",
       " 'baig',\n",
       " 'bailiff',\n",
       " 'bajarangabali',\n",
       " 'bak',\n",
       " 'bakra',\n",
       " 'bakrid',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'baller',\n",
       " 'balloon',\n",
       " 'balls',\n",
       " 'bam',\n",
       " 'bambling',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandage',\n",
       " 'bang',\n",
       " 'bangb',\n",
       " 'bangbabes',\n",
       " 'bani',\n",
       " 'bank',\n",
       " 'banneduk',\n",
       " 'banter',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbie',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bari',\n",
       " 'barkleys',\n",
       " 'barmed',\n",
       " 'barolla',\n",
       " 'barrel',\n",
       " 'barry',\n",
       " 'base',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'basq',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batchlor',\n",
       " 'bath',\n",
       " 'bathe',\n",
       " 'bathroom',\n",
       " 'batsman',\n",
       " 'batt',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bawl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbd',\n",
       " 'bbdeluxe',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bcaz',\n",
       " 'bck',\n",
       " 'bcm',\n",
       " 'bcmsfwc',\n",
       " 'bcoz',\n",
       " 'bcs',\n",
       " 'bcum',\n",
       " 'bcums',\n",
       " 'bcz',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'bear',\n",
       " 'bears',\n",
       " 'beat',\n",
       " 'beauties',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bec',\n",
       " 'becaus',\n",
       " 'becausethey',\n",
       " 'becoz',\n",
       " 'becz',\n",
       " 'bed',\n",
       " 'bedbut',\n",
       " 'bedreal',\n",
       " 'bedrm',\n",
       " 'bedroom',\n",
       " 'beeen',\n",
       " 'beehoon',\n",
       " 'beendropping',\n",
       " 'beer',\n",
       " 'beerage',\n",
       " 'beers',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'beggar',\n",
       " 'begin',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'bein',\n",
       " 'believe',\n",
       " 'belive',\n",
       " 'bell',\n",
       " 'bellearlier',\n",
       " 'belligerent',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belovd',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'beneficiary',\n",
       " 'benefit',\n",
       " 'bennys',\n",
       " 'bergkamp',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'betta',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'bettr',\n",
       " 'beverage',\n",
       " 'bevies',\n",
       " 'beware',\n",
       " 'bf',\n",
       " 'bffs',\n",
       " 'bfore',\n",
       " 'bhaji',\n",
       " 'bhamb',\n",
       " 'bhaskar',\n",
       " 'bhayandar',\n",
       " 'bian',\n",
       " 'biatch',\n",
       " 'bid',\n",
       " 'bids',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'billing',\n",
       " 'billion',\n",
       " 'billy',\n",
       " 'bilo',\n",
       " 'bimbo',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'bird',\n",
       " 'birla',\n",
       " 'biro',\n",
       " 'birth',\n",
       " 'birthdate',\n",
       " 'birthday',\n",
       " 'bishan',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bits',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blacko',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blastin',\n",
       " 'bleak',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blimey',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogging',\n",
       " 'blogspot',\n",
       " 'bloke',\n",
       " 'blokes',\n",
       " 'blonde',\n",
       " 'bloo',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'blu',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bluetoothhdset',\n",
       " 'bluff',\n",
       " 'blur',\n",
       " 'bluray',\n",
       " 'bmw',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boatin',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'boggy',\n",
       " 'bognor',\n",
       " 'bold',\n",
       " 'bollox',\n",
       " 'boltblue',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'bookedthe',\n",
       " 'bookmark',\n",
       " 'books',\n",
       " 'bookshelf',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'booty',\n",
       " 'bootydelious',\n",
       " 'borderline',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'borin',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bought',\n",
       " 'boundaries',\n",
       " 'bout',\n",
       " 'bowa',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boye',\n",
       " 'boyf',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'boytoy',\n",
       " 'bp',\n",
       " 'bpo',\n",
       " 'brah',\n",
       " 'brain',\n",
       " 'braindance',\n",
       " 'brainless',\n",
       " 'brainy',\n",
       " 'brand',\n",
       " 'brandy',\n",
       " 'bras',\n",
       " 'brats',\n",
       " 'brave',\n",
       " 'bray',\n",
       " 'brb',\n",
       " 'brdget',\n",
       " 'bread',\n",
       " 'breadstick',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakfast',\n",
       " 'breakin',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breather',\n",
       " 'breeze',\n",
       " 'breezy',\n",
       " 'brekkie',\n",
       " 'bremoved',\n",
       " 'bribe',\n",
       " 'bridal',\n",
       " 'bridge',\n",
       " 'bridgwater',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brin',\n",
       " 'bring',\n",
       " 'brisk',\n",
       " 'brison',\n",
       " 'bristol',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'broke',\n",
       " 'brolly',\n",
       " 'bros',\n",
       " 'broth',\n",
       " 'brothas',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownie',\n",
       " 'brownies',\n",
       " 'browse',\n",
       " 'browser',\n",
       " 'browsin',\n",
       " 'bruce',\n",
       " 'brum',\n",
       " 'bruv',\n",
       " 'bslvyl',\n",
       " 'bsn',\n",
       " 'bsnl',\n",
       " 'bstfrnd',\n",
       " 'bt',\n",
       " 'bthere',\n",
       " 'btw',\n",
       " 'btwn',\n",
       " 'bubbletext',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddy',\n",
       " 'buddys',\n",
       " 'budget',\n",
       " 'buen',\n",
       " 'buff',\n",
       " 'buffet',\n",
       " 'buffy',\n",
       " 'bugis',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bulbs',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bunch',\n",
       " 'bundle',\n",
       " 'bunker',\n",
       " 'buns',\n",
       " 'burden',\n",
       " 'burger',\n",
       " 'burgundy',\n",
       " 'burial',\n",
       " 'burn',\n",
       " 'burns',\n",
       " 'burrito',\n",
       " 'bus',\n",
       " 'busetop',\n",
       " 'business',\n",
       " 'busty',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'buttheres',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buz',\n",
       " 'buzy',\n",
       " 'buzz',\n",
       " 'buzzzz',\n",
       " 'bw',\n",
       " 'bx',\n",
       " 'byatch',\n",
       " 'bye',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cable',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calculate',\n",
       " 'calculation',\n",
       " 'cali',\n",
       " 'calicut',\n",
       " 'california',\n",
       " 'callback',\n",
       " 'callcost',\n",
       " 'calld',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'callers',\n",
       " 'callertune',\n",
       " 'callfreefone',\n",
       " 'callin',\n",
       " 'calling',\n",
       " 'callon',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camcorder',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campus',\n",
       " 'camry',\n",
       " 'canada',\n",
       " 'canal',\n",
       " 'canary',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'canlove',\n",
       " 'cann',\n",
       " 'canname',\n",
       " 'cantdo',\n",
       " 'canteen',\n",
       " 'cap',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'cappuccino',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardiff',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'careabout',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'careless',\n",
       " 'carlie',\n",
       " 'carlin',\n",
       " 'carlos',\n",
       " 'carly',\n",
       " 'carolina',\n",
       " 'caroline',\n",
       " 'carpark',\n",
       " 'carry',\n",
       " 'carryin',\n",
       " 'cars',\n",
       " 'cartons',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashbin',\n",
       " 'cashto',\n",
       " 'cast',\n",
       " 'castor',\n",
       " 'casualty',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'categories',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cave',\n",
       " 'caveboy',\n",
       " 'cbe',\n",
       " 'cc',\n",
       " 'ccna',\n",
       " 'cd',\n",
       " 'cdgt',\n",
       " 'cds',\n",
       " 'cedar',\n",
       " 'ceiling',\n",
       " 'celeb',\n",
       " 'celebrate',\n",
       " 'celebrated',\n",
       " 'celebration',\n",
       " 'celebrations',\n",
       " 'cell',\n",
       " 'census',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'century',\n",
       " 'cer',\n",
       " 'cereals',\n",
       " 'ceri',\n",
       " 'certainly',\n",
       " 'certificate',\n",
       " 'cfca',\n",
       " 'ch',\n",
       " 'cha',\n",
       " 'chachi',\n",
       " 'chad',\n",
       " 'chain',\n",
       " 'challenge',\n",
       " 'champ',\n",
       " 'champlaxigating',\n",
       " 'champneys',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chap',\n",
       " 'chapel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'charles',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chasing',\n",
       " 'chastity',\n",
       " 'chat',\n",
       " 'chatlines',\n",
       " 'chatter',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'chechi',\n",
       " 'check',\n",
       " 'checkboxes',\n",
       " 'checkin',\n",
       " 'checkmate',\n",
       " 'checkup',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'cheered',\n",
       " 'cheers',\n",
       " 'cheery',\n",
       " 'cheese',\n",
       " 'cheesy',\n",
       " 'cheetos',\n",
       " 'chef',\n",
       " 'chennai',\n",
       " 'cheque',\n",
       " 'cherish',\n",
       " 'cherthala',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'chex',\n",
       " 'cheyyamo',\n",
       " 'chez',\n",
       " 'chg',\n",
       " 'chgs',\n",
       " 'chic',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chickened',\n",
       " 'chief',\n",
       " 'chik',\n",
       " 'chikku',\n",
       " 'child',\n",
       " 'childish',\n",
       " 'childporn',\n",
       " 'children',\n",
       " 'childrens',\n",
       " 'chile',\n",
       " 'chill',\n",
       " 'chillaxin',\n",
       " 'chillin',\n",
       " 'china',\n",
       " 'chinatown',\n",
       " 'chinchillas',\n",
       " 'chinese',\n",
       " ...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 6750)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 5627)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # remember to use the original X_train set\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794871794871796"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = cross_val_score(clf, X_train_tfidf,y_train,scoring=\"accuracy\", cv=10)\n",
    "scores= cv_score.mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812820512820514"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = cross_val_score(clf, X_train_counts,y_train,scoring=\"accuracy\", cv=10)\n",
    "scores= cv_score.mean()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986244019138756\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvect', CountVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVec\n",
    "text_clf = Pipeline([('countvect', CountVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892344497607656\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', CountVectorizer(stop_words='english')),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVec with stop word ()\n",
    "text_clf = Pipeline([('tfidf', CountVectorizer(stop_words='english')),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838516746411483\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-4ccddb82314a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 242\u001b[0;31m     scores = parallel(\n\u001b[0m\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    242\u001b[0m     scores = parallel(\n\u001b[1;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 raise TypeError(\"Cannot clone object. \" +\n\u001b[0m\u001b[1;32m     75\u001b[0m                                 \u001b[0;34m\"You should provide an instance of \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object. You should provide an instance of scikit-learn estimator instead of a class."
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(Pipeline, X_train, y_train,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8713)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(sms['message']) # remember to use the original X_train set\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7004"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3900x7263 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 52150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =sms['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdm(data):\n",
    "    vec = CountVectorizer()\n",
    "    X = vec.fit_transform(data)\n",
    "    df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "    return df\n",
    "\n",
    "def find_principal_components(n, data):\n",
    "    pca = PCA(n_components = n)\n",
    "    principalComponents = pca.fit_transform(data)\n",
    "    return pd.DataFrame(pca.components_, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada  \\\n",
       "0              0   0  ...      0       0    0          0     0     0      0   \n",
       "1              0   0  ...      0       0    0          0     0     0      0   \n",
       "2              0   0  ...      0       0    0          0     0     0      0   \n",
       "3              0   0  ...      0       0    0          0     0     0      0   \n",
       "4              0   0  ...      0       0    0          0     0     0      0   \n",
       "...          ...  ..  ...    ...     ...  ...        ...   ...   ...    ...   \n",
       "5567           0   0  ...      0       0    0          0     0     0      0   \n",
       "5568           0   0  ...      0       0    0          0     0     0      0   \n",
       "5569           0   0  ...      0       0    0          0     0     0      0   \n",
       "5570           0   0  ...      0       0    0          0     0     0      0   \n",
       "5571           0   0  ...      0       0    0          0     0     0      0   \n",
       "\n",
       "      èn  ú1  〨ud  \n",
       "0      0   0    0  \n",
       "1      0   0    0  \n",
       "2      0   0    0  \n",
       "3      0   0    0  \n",
       "4      0   0    0  \n",
       "...   ..  ..  ...  \n",
       "5567   0   0    0  \n",
       "5568   0   0    0  \n",
       "5569   0   0    0  \n",
       "5570   0   0    0  \n",
       "5571   0   0    0  \n",
       "\n",
       "[5572 rows x 8713 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>ú1</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0      0    0       0             0     0     0            0            0   \n",
       "1      0    0       0             0     0     0            0            0   \n",
       "2      0    0       0             0     0     0            0            0   \n",
       "3      0    0       0             0     0     0            0            0   \n",
       "4      0    0       0             0     0     0            0            0   \n",
       "...   ..  ...     ...           ...   ...   ...          ...          ...   \n",
       "5567   0    0       0             0     0     0            0            0   \n",
       "5568   0    0       0             0     0     0            0            0   \n",
       "5569   0    0       0             0     0     0            0            0   \n",
       "5570   0    0       0             0     0     0            0            0   \n",
       "5571   0    0       0             0     0     0            0            0   \n",
       "\n",
       "      0125698789  02  ...  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada  \\\n",
       "0              0   0  ...      0       0    0          0     0     0      0   \n",
       "1              0   0  ...      0       0    0          0     0     0      0   \n",
       "2              0   0  ...      0       0    0          0     0     0      0   \n",
       "3              0   0  ...      0       0    0          0     0     0      0   \n",
       "4              0   0  ...      0       0    0          0     0     0      0   \n",
       "...          ...  ..  ...    ...     ...  ...        ...   ...   ...    ...   \n",
       "5567           0   0  ...      0       0    0          0     0     0      0   \n",
       "5568           0   0  ...      0       0    0          0     0     0      0   \n",
       "5569           0   0  ...      0       0    0          0     0     0      0   \n",
       "5570           0   0  ...      0       0    0          0     0     0      0   \n",
       "5571           0   0  ...      0       0    0          0     0     0      0   \n",
       "\n",
       "      èn  ú1  〨ud  \n",
       "0      0   0    0  \n",
       "1      0   0    0  \n",
       "2      0   0    0  \n",
       "3      0   0    0  \n",
       "4      0   0    0  \n",
       "...   ..  ..  ...  \n",
       "5567   0   0    0  \n",
       "5568   0   0    0  \n",
       "5569   0   0    0  \n",
       "5570   0   0    0  \n",
       "5571   0   0    0  \n",
       "\n",
       "[5572 rows x 8713 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tdm(X)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tdm(X)\n",
    "principalDF = find_principal_components(6, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         00       000    000pes  008704050406      0089      0121  \\\n",
      "0 -0.000069  0.001778 -0.000101      0.000131  0.000134 -0.000070   \n",
      "1  0.002696  0.002610  0.000015      0.000821  0.000400  0.000098   \n",
      "2 -0.002762 -0.008034  0.000145      0.000221 -0.000552  0.000142   \n",
      "3  0.000119  0.004610 -0.000089      0.000035 -0.000212  0.000154   \n",
      "4 -0.001493 -0.010098  0.000172     -0.000734  0.000090 -0.000548   \n",
      "5 -0.000318 -0.001307  0.000441      0.000063 -0.000386 -0.000175   \n",
      "\n",
      "   01223585236  01223585334  0125698789        02  ...     zhong    zindgi  \\\n",
      "0     0.000019     0.000176   -0.000090  0.000902  ...  0.000072 -0.000307   \n",
      "1     0.000092     0.000986    0.000017  0.000345  ... -0.000258 -0.000102   \n",
      "2     0.000334    -0.001017    0.000168 -0.001225  ...  0.000101 -0.000086   \n",
      "3    -0.000646    -0.000426   -0.000482  0.002014  ... -0.000431  0.000027   \n",
      "4     0.000592     0.000190    0.000452 -0.003825  ...  0.000596 -0.000072   \n",
      "5    -0.000196    -0.000150   -0.000286 -0.000629  ...  0.000175  0.000040   \n",
      "\n",
      "        zoe  zogtorius      zoom      zouk     zyada        èn        ú1  \\\n",
      "0  0.000004   0.000072  0.000029 -0.000135 -0.000153 -0.000043  0.000085   \n",
      "1  0.000520   0.000383  0.000274 -0.000012 -0.000051  0.000127  0.000544   \n",
      "2 -0.000299   0.000118 -0.000120 -0.000042 -0.000043  0.000214 -0.000310   \n",
      "3 -0.000587  -0.000170 -0.000156  0.000028  0.000014  0.000136  0.000031   \n",
      "4  0.000478  -0.000155  0.000132 -0.000105 -0.000036 -0.000433 -0.000357   \n",
      "5  0.000143  -0.000464  0.000091 -0.000061  0.000020 -0.000114  0.000007   \n",
      "\n",
      "        〨ud  \n",
      "0  0.000457  \n",
      "1 -0.000515  \n",
      "2 -0.000285  \n",
      "3  0.000101  \n",
      "4  0.000152  \n",
      "5  0.000425  \n",
      "\n",
      "[6 rows x 8713 columns]\n"
     ]
    }
   ],
   "source": [
    "print(principalDF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-94b2630ba532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \"\"\"\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['label'] = LabelEncoder().fit_transform(sms['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['text'] = sms.text.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     int64\n",
       "text     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-671deb2a0cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#List of all SMS texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdocumentList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# #Frequency count matrix of all words in SMS texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcountMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "#List of all SMS texts\n",
    "documentList = df['text']\n",
    "vect = CountVectorizer()\n",
    "# #Frequency count matrix of all words in SMS texts\n",
    "countMatrix = vect.fit_transform(sms['text'])\n",
    "tokenizedDf = pd.DataFrame(countMatrix.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "# #Encoding SMS texts for ML algorithms\n",
    "resultEncodingDict = {'ham': 1, 'spam': 0}\n",
    "resultList = df['label']\n",
    "resultList.replace(sms['label'], inplace=True)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(tokenizedDf, resultList, test_size=.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy array of frequency counts on tokenized SMS texts\n",
    "frequencyCounts = tokenizedDf.values\n",
    "#Encoded 'spam'/'ham' Series\n",
    "encodedClassication = resultList.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing frequency count matrix\n",
    "standardizedFreqCounts = StandardScaler().fit_transform(frequencyCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000)\n",
    "princComp = pca.fit_transform(standardizedFreqCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.063700</td>\n",
       "      <td>-0.151997</td>\n",
       "      <td>-0.428451</td>\n",
       "      <td>-0.037529</td>\n",
       "      <td>-0.087692</td>\n",
       "      <td>0.062612</td>\n",
       "      <td>-1.418072</td>\n",
       "      <td>1.232113</td>\n",
       "      <td>-0.395863</td>\n",
       "      <td>-0.687086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634363</td>\n",
       "      <td>0.648301</td>\n",
       "      <td>-0.080094</td>\n",
       "      <td>0.132614</td>\n",
       "      <td>0.158259</td>\n",
       "      <td>-0.249270</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>-0.243263</td>\n",
       "      <td>-0.286212</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002856</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>-0.772006</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>0.095139</td>\n",
       "      <td>-0.963170</td>\n",
       "      <td>0.896465</td>\n",
       "      <td>-0.519916</td>\n",
       "      <td>-0.423579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276518</td>\n",
       "      <td>-0.829071</td>\n",
       "      <td>-0.386821</td>\n",
       "      <td>0.692552</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.751970</td>\n",
       "      <td>-0.033644</td>\n",
       "      <td>-0.478489</td>\n",
       "      <td>1.394037</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.193925</td>\n",
       "      <td>-0.327665</td>\n",
       "      <td>-2.965923</td>\n",
       "      <td>-1.002291</td>\n",
       "      <td>-0.526362</td>\n",
       "      <td>-1.369539</td>\n",
       "      <td>5.621494</td>\n",
       "      <td>-11.278865</td>\n",
       "      <td>4.266407</td>\n",
       "      <td>2.066188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145334</td>\n",
       "      <td>-0.087124</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>-0.233177</td>\n",
       "      <td>-0.304071</td>\n",
       "      <td>-0.191022</td>\n",
       "      <td>-0.207484</td>\n",
       "      <td>0.087511</td>\n",
       "      <td>0.140312</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.018175</td>\n",
       "      <td>-0.103427</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>0.096362</td>\n",
       "      <td>-0.074618</td>\n",
       "      <td>0.145494</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>1.115756</td>\n",
       "      <td>-0.712510</td>\n",
       "      <td>0.292906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244631</td>\n",
       "      <td>-1.082838</td>\n",
       "      <td>-0.709429</td>\n",
       "      <td>0.499596</td>\n",
       "      <td>-1.979566</td>\n",
       "      <td>0.924328</td>\n",
       "      <td>-1.126544</td>\n",
       "      <td>-2.411456</td>\n",
       "      <td>-1.626524</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062648</td>\n",
       "      <td>-0.128259</td>\n",
       "      <td>0.552869</td>\n",
       "      <td>0.044315</td>\n",
       "      <td>0.077306</td>\n",
       "      <td>0.089443</td>\n",
       "      <td>-0.930814</td>\n",
       "      <td>0.934571</td>\n",
       "      <td>-0.651575</td>\n",
       "      <td>-0.555858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107261</td>\n",
       "      <td>2.047341</td>\n",
       "      <td>0.399520</td>\n",
       "      <td>-0.152317</td>\n",
       "      <td>1.050076</td>\n",
       "      <td>-0.573644</td>\n",
       "      <td>0.419450</td>\n",
       "      <td>2.750305</td>\n",
       "      <td>-1.632001</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.063700 -0.151997 -0.428451 -0.037529 -0.087692  0.062612 -1.418072   \n",
       "1 -0.002856 -0.104463 -0.772006  0.001415 -0.016176  0.095139 -0.963170   \n",
       "2 -0.193925 -0.327665 -2.965923 -1.002291 -0.526362 -1.369539  5.621494   \n",
       "3 -0.018175 -0.103427  0.122268  0.096362 -0.074618  0.145494 -0.999944   \n",
       "4  0.062648 -0.128259  0.552869  0.044315  0.077306  0.089443 -0.930814   \n",
       "\n",
       "           7         8         9  ...      1991      1992      1993      1994  \\\n",
       "0   1.232113 -0.395863 -0.687086  ... -0.634363  0.648301 -0.080094  0.132614   \n",
       "1   0.896465 -0.519916 -0.423579  ...  0.276518 -0.829071 -0.386821  0.692552   \n",
       "2 -11.278865  4.266407  2.066188  ... -0.145334 -0.087124  0.002723 -0.233177   \n",
       "3   1.115756 -0.712510  0.292906  ...  0.244631 -1.082838 -0.709429  0.499596   \n",
       "4   0.934571 -0.651575 -0.555858  ... -0.107261  2.047341  0.399520 -0.152317   \n",
       "\n",
       "       1995      1996      1997      1998      1999  classification  \n",
       "0  0.158259 -0.249270  0.399498 -0.243263 -0.286212             ham  \n",
       "1  0.317460  0.751970 -0.033644 -0.478489  1.394037             ham  \n",
       "2 -0.304071 -0.191022 -0.207484  0.087511  0.140312            spam  \n",
       "3 -1.979566  0.924328 -1.126544 -2.411456 -1.626524             ham  \n",
       "4  1.050076 -0.573644  0.419450  2.750305 -1.632001             ham  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatinating pc1, pc2, and encoded classification array\n",
    "#princDf = pd.DataFrame(princComp, columns=['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9', 'pc10'])\n",
    "princDf = pd.DataFrame(princComp)\n",
    "mergedPrincDf = pd.concat([princDf, pd.Series(encodedClassication, name='classification')], axis=1)\n",
    "mergedPrincDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varience explained by pc1 is: 0.213%\n",
      "Varience explained by pc2 is: 0.211%\n",
      "Varience explained by pc3 is: 0.182%\n",
      "Varience explained by pc4 is: 0.177%\n",
      "Varience explained by pc5 is: 0.174%\n",
      "Varience explained by pc6 is: 0.172%\n",
      "Varience explained by pc7 is: 0.167%\n",
      "Varience explained by pc8 is: 0.159%\n",
      "Varience explained by pc9 is: 0.158%\n",
      "Varience explained by pc10 is: 0.153%\n"
     ]
    }
   ],
   "source": [
    "#Looking at varience each explained by PC1 and PC2\n",
    "pc1Var, pc2Var,pc3Var,pc4Var,pc5Var, pc6Var,pc7Var,pc8Var,pc9Var, pc10Var,pc11Var, pc12Var,pc13Var,pc14Var,pc15Var, pc16Var,pc17Var,pc18Var,pc19Var, pc20Var  = pca.explained_variance_ratio_\n",
    "print(f'Varience explained by pc1 is: {pc1Var*100:.3f}%')\n",
    "print(f'Varience explained by pc2 is: {pc2Var*100:.3f}%')\n",
    "print(f'Varience explained by pc3 is: {pc3Var*100:.3f}%')\n",
    "print(f'Varience explained by pc4 is: {pc4Var*100:.3f}%')\n",
    "print(f'Varience explained by pc5 is: {pc5Var*100:.3f}%')\n",
    "print(f'Varience explained by pc6 is: {pc6Var*100:.3f}%')\n",
    "print(f'Varience explained by pc7 is: {pc7Var*100:.3f}%')\n",
    "print(f'Varience explained by pc8 is: {pc8Var*100:.3f}%')\n",
    "print(f'Varience explained by pc9 is: {pc9Var*100:.3f}%')\n",
    "print(f'Varience explained by pc10 is: {pc10Var*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained = np.cumsum(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.53004459, 17.3078296 , 14.94273703, ...,  1.19012911,\n",
       "        1.18643036,  1.18309656])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative explained variance')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "plt.plot(range(2000),variance_explained, color='r')\n",
    "ax.grid(True)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_rescaled)\n",
    "pcx = pca.transform(X_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5574, 3901]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-b23a696078c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprincComp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0m\u001b[1;32m    161\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                                        accept_large_sparse=False)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5574, 3901]"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='auto')\n",
    "svc.fit(princComp, yTrain)\n",
    "accuracy_score(yTest, svc.predict(xTest))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-cb6475d812d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Plotting data, to get a visual representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Adding x and y labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PC1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting data, to get a visual representation\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "#Adding x and y labels\n",
    "ax.set_xlabel('PC1', fontsize=15)\n",
    "ax.set_ylabel('PC2', fontsize=15)\n",
    "#Adding title\n",
    "ax.set_title('2-Component PCA Chart', fontsize=20)\n",
    "\n",
    "classifications = [1, 0]\n",
    "colors = ['b', 'r']\n",
    "#Plotting scatter graph\n",
    "for classification, color in zip(classifications, colors):\n",
    "    indicesToKeep = mergedPrincDf['classification'] == classification\n",
    "    ax.scatter(mergedPrincDf.loc[indicesToKeep, 'pc1'], \n",
    "               mergedPrincDf.loc[indicesToKeep, 'pc2'], \n",
    "               c=color, s=50)\n",
    "    \n",
    "ax.legend(classifications)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e89dbff7d09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "text = sms['text']\n",
    "vect = CountVectorizer()\n",
    "count = vect.fit_transform(text)\n",
    "tokenized = pd.DataFrame(countMatrix.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "result = sms['classification']\n",
    "result.replace(resultEncodingDict, inplace=True)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(tokenized, result, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c476eeff8d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtfidf_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \"\"\"\n\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "text = list(sms['text'])\n",
    "labels = sms['label']\n",
    "\n",
    "tfidf_reviews = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Go until jurong point crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4d25574bfe02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[1;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Go until jurong point crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(sms['text'])\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 11, step=1)\n",
    "y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 11, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
